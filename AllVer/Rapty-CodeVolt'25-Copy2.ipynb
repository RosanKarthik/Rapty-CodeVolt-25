{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba61479-72e9-4b90-bd2a-7b005d3471ea",
   "metadata": {},
   "source": [
    "## Libraries And Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eefd1351-5b15-4972-9077-439c779aad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import gc\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import googlemaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d2c2e-fbea-49b1-b103-29c98cdea9e6",
   "metadata": {},
   "source": [
    "## FunctionDefinitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea55ba0-87fc-4180-b919-642e0db90ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_gpu_memory():\n",
    "  \"\"\"\n",
    "  Releases GPU memory occupied by PyTorch tensors and cached allocations.\n",
    "  \"\"\"\n",
    "  # Delete any unused PyTorch tensors\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "  # Trigger garbage collection to potentially release unreferenced objects\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9101df11-6afb-42a0-b21e-8fe38e80653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1  # 0 for GPU, -1 for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0462019f-ed7f-4147-a853-c6b518d6ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key=\"AIzaSyBO_d9rDxgC87qPhzCjsLTQS17JArcmte4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39d9ada-c4b6-4cd5-be36-bd0f3753ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_route(origin, destination):\n",
    "    directions = gmaps.directions(origin, destination, mode=\"driving\", alternatives=False)\n",
    "    if directions:\n",
    "        route = directions[0]['legs'][0]\n",
    "        distance = route['distance']['text']\n",
    "        duration = route['duration']['text']\n",
    "        steps = [step['html_instructions'] for step in route['steps']]\n",
    "        return distance, duration, steps\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091388e6-1e29-405c-a243-fef0db3b357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decide if Google Maps API should be used\n",
    "def process_user_prompt(user_prompt):\n",
    "    keywords = [\"shortest distance\", \"shortest route\", \"how far\", \"travel time\"]\n",
    "    \n",
    "    if any(keyword in user_prompt.lower() for keyword in keywords):\n",
    "        # Extract location names from user prompt (Assuming format: \"shortest distance from X to Y\")\n",
    "        parts = user_prompt.split(\" from \")\n",
    "        if len(parts) > 1 and \" to \" in parts[1]:\n",
    "            locations = parts[1].split(\" to \")\n",
    "            origin, destination = locations[0], locations[1]\n",
    "            \n",
    "            distance, duration = get_shortest_distance(origin, destination)\n",
    "            \n",
    "            if distance:\n",
    "                prompt = f\"The shortest driving distance from {origin} to {destination} is {distance} and takes around {duration}.\"\n",
    "            else:\n",
    "                prompt = f\"Sorry, I couldn't find the shortest route from {origin} to {destination}.\"\n",
    "        else:\n",
    "            prompt = \"I need both starting and ending locations to find the shortest distance.\"\n",
    "    else:\n",
    "        # If it's not a route-related question, generate a normal AI response\n",
    "        prompt = user_prompt\n",
    "        # get_deepseek_response(prompt)\n",
    "        \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=200)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58fbc75-5d29-494e-83a2-77d05ba1f799",
   "metadata": {},
   "source": [
    "## WhisperTranscription(SpeechToText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c729c19c-fd1d-49d6-993b-293462b3eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file_path, model_type, language):\n",
    "    model = whisper.load_model(model_type)\n",
    "    result = model.transcribe(file_path,\n",
    "                              language=language,\n",
    "                              task=\"transcribe\",\n",
    "                              )\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd37015d-33cd-484c-97c8-2fa81ea953a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English :  How far is Annanagar from Tambaram?\n"
     ]
    }
   ],
   "source": [
    "file_path = \"AnnaToTambaram.m4a\"\n",
    "en_transcribed_text = transcribe_audio(file_path, \"medium\", language=\"en\")\n",
    "print(\"English :\", en_transcribed_text)\n",
    "\n",
    "free_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a355ca0-5222-456e-bbf0-e003e1bdeaf6",
   "metadata": {},
   "source": [
    "## LLMLoading(DeepSeekR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c28b1d7a-3e4f-4d5b-98cd-f3adabf42d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5831dc82-d2fd-4eb1-b00e-dbb7c2722c71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ApiError",
     "evalue": "REQUEST_DENIED (This API project is not authorized to use this API.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mApiError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Example Usage\u001b[39;00m\n\u001b[0;32m     63\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the shortest distance from T-Nagar to Marina Beach?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 64\u001b[0m ai_response \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_user_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(ai_response)\n",
      "Cell \u001b[1;32mIn[12], line 32\u001b[0m, in \u001b[0;36mprocess_user_prompt\u001b[1;34m(user_prompt)\u001b[0m\n\u001b[0;32m     29\u001b[0m locations \u001b[38;5;241m=\u001b[39m parts[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m origin, destination \u001b[38;5;241m=\u001b[39m locations[\u001b[38;5;241m0\u001b[39m], locations[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 32\u001b[0m distance, duration \u001b[38;5;241m=\u001b[39m \u001b[43mget_shortest_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m distance:\n\u001b[0;32m     35\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shortest driving distance from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morigin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistance\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and takes around \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m, in \u001b[0;36mget_shortest_distance\u001b[1;34m(origin, destination)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_shortest_distance\u001b[39m(origin, destination):\n\u001b[1;32m---> 10\u001b[0m     directions \u001b[38;5;241m=\u001b[39m \u001b[43mgmaps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirections\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdriving\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malternatives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m directions:\n\u001b[0;32m     12\u001b[0m         route \u001b[38;5;241m=\u001b[39m directions[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlegs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mD:\\CodeVolt'25\\rapty\\lib\\site-packages\\googlemaps\\client.py:445\u001b[0m, in \u001b[0;36mmake_api_method.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    444\u001b[0m     args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_extra_params \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_params\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 445\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_extra_params\n",
      "File \u001b[1;32mD:\\CodeVolt'25\\rapty\\lib\\site-packages\\googlemaps\\directions.py:153\u001b[0m, in \u001b[0;36mdirections\u001b[1;34m(client, origin, destination, mode, waypoints, alternatives, avoid, language, units, region, departure_time, arrival_time, optimize_waypoints, transit_mode, transit_routing_preference, traffic_model)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m traffic_model:\n\u001b[0;32m    151\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraffic_model\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m traffic_model\n\u001b[1;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/maps/api/directions/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroutes\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[1;32mD:\\CodeVolt'25\\rapty\\lib\\site-packages\\googlemaps\\client.py:340\u001b[0m, in \u001b[0;36mClient._request\u001b[1;34m(self, url, params, first_request_time, retry_counter, base_url, accepts_clientid, extract_body, requests_kwargs, post_json)\u001b[0m\n\u001b[0;32m    338\u001b[0m     result \u001b[38;5;241m=\u001b[39m extract_body(response)\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msent_times\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime())\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\CodeVolt'25\\rapty\\lib\\site-packages\\googlemaps\\client.py:369\u001b[0m, in \u001b[0;36mClient._get_body\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOVER_QUERY_LIMIT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m googlemaps\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39m_OverQueryLimit(\n\u001b[0;32m    367\u001b[0m         api_status, body\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror_message\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m--> 369\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m googlemaps\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mApiError(api_status,\n\u001b[0;32m    370\u001b[0m                                      body\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror_message\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mApiError\u001b[0m: REQUEST_DENIED (This API project is not authorized to use this API.)"
     ]
    }
   ],
   "source": [
    "import googlemaps\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Initialize Google Maps API client\n",
    "gmaps = googlemaps.Client(key=\"AIzaSyBO_d9rDxgC87qPhzCjsLTQS17JArcmte4\")\n",
    "\n",
    "# Function to get the shortest distance\n",
    "def get_shortest_distance(origin, destination):\n",
    "    directions = gmaps.directions(origin, destination, mode=\"driving\", alternatives=False)\n",
    "    if directions:\n",
    "        route = directions[0]['legs'][0]\n",
    "        return route['distance']['text'], route['duration']['text']\n",
    "    return None, None\n",
    "\n",
    "# Initialize DeepSeek AI Model\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Function to decide if Google Maps API should be used\n",
    "def process_user_prompt(user_prompt):\n",
    "    keywords = [\"shortest distance\", \"shortest route\", \"how far\", \"travel time\"]\n",
    "    \n",
    "    if any(keyword in user_prompt.lower() for keyword in keywords):\n",
    "        # Extract location names from user prompt\n",
    "        parts = user_prompt.split(\" from \")\n",
    "        if len(parts) > 1 and \" to \" in parts[1]:\n",
    "            locations = parts[1].split(\" to \")\n",
    "            origin, destination = locations[0], locations[1]\n",
    "            \n",
    "            distance, duration = get_shortest_distance(origin, destination)\n",
    "            \n",
    "            if distance:\n",
    "                prompt = f\"The shortest driving distance from {origin} to {destination} is {distance} and takes around {duration}.\"\n",
    "            else:\n",
    "                prompt = f\"Sorry, I couldn't find the shortest route from {origin} to {destination}.\"\n",
    "        else:\n",
    "            prompt = \"I need both starting and ending locations to find the shortest distance.\"\n",
    "    else:\n",
    "        # If it's not a route-related question, generate a normal AI response\n",
    "        prompt = user_prompt\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate response with repetition penalty and limited tokens\n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=200,  \n",
    "        repetition_penalty=1.2,  # Reduce repetition\n",
    "        temperature=0.7  # Reduce randomness\n",
    "    )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Prevent infinite loops by detecting repeating patterns\n",
    "    if response.count(\"shortest path between two points on a grid\") > 3:\n",
    "        response = \"I think you're asking about the shortest path, but I need more details. Are you referring to real-world routes or a grid-based system?\"\n",
    "\n",
    "    return response\n",
    "\n",
    "# Example Usage\n",
    "user_input = \"What is the shortest distance from T-Nagar to Marina Beach?\"\n",
    "ai_response = process_user_prompt(user_input)\n",
    "\n",
    "print(ai_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecb2ae65-1343-4267-8360-643840b004ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure PAD token is set correctly\n",
    "tokenizer.pad_token = tokenizer.eos_token  \n",
    "\n",
    "# Function to get a concise response from DeepSeek\n",
    "def get_deepseek_response(prompt):\n",
    "    system_prompt = (\"You are an AI assistant that provides concise and direct answers. \"\n",
    "                     \"Do not include unnecessary thoughts or self-reflections. \"\n",
    "                     \"Give factual and to-the-point responses.\")\n",
    "\n",
    "    full_prompt = f\"{system_prompt}\\n\\nUser: {prompt}\\nAI:\"\n",
    "\n",
    "    # Tokenize input with attention mask\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,  # Explicitly pass attention mask\n",
    "            max_new_tokens=100,  # Limits response length\n",
    "            temperature=0.3,  # Reduces randomness for factual responses\n",
    "            top_k=40,  # Ensures relevant words are chosen\n",
    "            repetition_penalty=1.05,  # Prevents repetition\n",
    "            eos_token_id=tokenizer.eos_token_id  # Stops generation at the end\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Remove system prompt from response\n",
    "    return response.replace(full_prompt, \"\").strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5509524-2d26-48f0-832f-73dca020b5e0",
   "metadata": {},
   "source": [
    "## DeepSeek Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0aee785f-851b-400c-8483-68629892838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need both starting and ending locations to find the shortest distance. I need to find the shortest distance between two points on a coordinate plane. How do I do this?\n",
      "\n",
      "I'm trying to figure out how to find the shortest distance between two points on a coordinate plane. I remember that it's something to do with the distance formula, but I'm not entirely sure how to apply it. Let me think... The distance formula is... hmmm, I think it's something like the square root of the sum of the squares of the differences in the x and y coordinates. So, if I have two points, say (x1, y1) and (x2, y2), then the distance between them would be sqrt[(x2 - x1)^2 + (y2 - y1)^2]. Is that right? I think so, but I want to make sure. Maybe I can visualize it. Imagine two points on a coordinate plane; to find the straight line distance between them, I can imagine a right triangle where the two legs\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"Tell me about a tourist spot near T-Nagar, Chennai\"\n",
    "\n",
    "prompt=en_transcribed_text\n",
    "deepseek_response = process_user_prompt(prompt)\n",
    "\n",
    "print(deepseek_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b26483-629f-4e25-a402-7876416408fb",
   "metadata": {},
   "source": [
    "## PyTTS(TextToSpeech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d67c4b2-bf85-4458-b55b-040365d0d82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate :  200\n",
      "Volume :  1.0\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3 as tts\n",
    "engine = tts.init() # object creation\n",
    "\n",
    "\"\"\" RATE\"\"\"\n",
    "rate = engine.getProperty('rate')   # getting details of current speaking rate\n",
    "print (\"Rate : \",rate)                        #printing current voice rate\n",
    "engine.setProperty('rate', 125)     # setting up new voice rate\n",
    "\n",
    "\n",
    "\"\"\"VOLUME\"\"\"\n",
    "volume = engine.getProperty('volume')   #getting to know current volume level (min=0 and max=1)\n",
    "print (\"Volume : \",volume)                          #printing current volume level\n",
    "engine.setProperty('volume',1.0)    # setting up volume level  between 0 and 1\n",
    "\n",
    "\"\"\"VOICE\"\"\"\n",
    "voices = engine.getProperty('voices')       #getting details of current voice\n",
    "#engine.setProperty('voice', voices[0].id)  #changing index, changes voices. o for male\n",
    "engine.setProperty('voice', voices[0].id)   #changing index, changes voices. 1 for female\n",
    "\n",
    "engine.say(deepseek_response)\n",
    "engine.say('My current speaking rate is ' + str(rate))\n",
    "engine.runAndWait()\n",
    "if engine._inLoop:\n",
    "    engine.endLoop()\n",
    "engine.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
