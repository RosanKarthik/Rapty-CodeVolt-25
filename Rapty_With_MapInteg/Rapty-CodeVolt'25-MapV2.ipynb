{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba61479-72e9-4b90-bd2a-7b005d3471ea",
   "metadata": {},
   "source": [
    "## Libraries And Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eefd1351-5b15-4972-9077-439c779aad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import gc\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import googlemaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d2c2e-fbea-49b1-b103-29c98cdea9e6",
   "metadata": {},
   "source": [
    "## Functions&Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea55ba0-87fc-4180-b919-642e0db90ddb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#GARBAGE_COLLECTION\n",
    "def free_gpu_memory():\n",
    "  \"\"\"\n",
    "  Releases GPU memory occupied by PyTorch tensors and cached allocations.\n",
    "  \"\"\"\n",
    "  # Delete any unused PyTorch tensors\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "  # Trigger garbage collection to potentially release unreferenced objects\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea646d5e-3f99-4e9e-ac16-50626f49ac81",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Google_API_KEY\n",
    "GOOGLE_MAPS_API_KEY = \"YOURAPIKEY\"\n",
    "gmaps = googlemaps.Client(key=GOOGLE_MAPS_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9101df11-6afb-42a0-b21e-8fe38e80653a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#DEVICE_SELECTION\n",
    "device = 0 if torch.cuda.is_available() else -1  # 0 for GPU, -1 for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0de41ae0-b7af-4713-8a16-8af2b7f08b3b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract shortest route using Google Maps API\n",
    "def get_shortest_distance(origin, destination):\n",
    "    try:\n",
    "        directions = gmaps.directions(origin, destination, mode=\"driving\", alternatives=False)\n",
    "        if directions:\n",
    "            route = directions[0]['legs'][0]\n",
    "            return route['distance']['text'], route['duration']['text']\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        return None, None  # Prevents API errors from crashing the script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "891ce6a1-f882-4d0d-bcf4-7a763f4619dd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to generate AI response using DeepSeek\n",
    "def get_deepseek_response(prompt):\n",
    "    system_prompt = (\"You are an AI assistant that provides concise and direct answers. \"\n",
    "                     \"Avoid unnecessary self-reflections. Provide factual responses.\")\n",
    "\n",
    "    full_prompt = f\"{system_prompt}\\n\\nUser: {prompt}\\nAI:\"\n",
    "\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,  \n",
    "            max_new_tokens=100,  \n",
    "            temperature=0.3,  \n",
    "            top_k=40,  \n",
    "            repetition_penalty=1.05,  \n",
    "            eos_token_id=tokenizer.eos_token_id  \n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return response.replace(full_prompt, \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae9971e8-95e5-4908-a5c6-952a01c17486",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to decide if Google Maps API should be used or DeepSeek AI\n",
    "def process_user_prompt(user_prompt):\n",
    "    travel_keywords = [\"shortest distance\", \"shortest route\", \"how far\", \"travel time\", \"directions to\", \"get to\"]\n",
    "\n",
    "    if any(keyword in user_prompt.lower() for keyword in travel_keywords):\n",
    "        # Extracting locations intelligently\n",
    "        words = user_prompt.lower().replace(\"to\", \"|\").replace(\"from\", \"|\").split(\"|\")\n",
    "        if len(words) >= 2:\n",
    "            origin, destination = words[-2].strip(), words[-1].strip()\n",
    "        else:\n",
    "            return \"I need both a starting point and a destination.\"\n",
    "\n",
    "        distance, duration = get_shortest_distance(origin, destination)\n",
    "\n",
    "        if distance:\n",
    "            return f\"The shortest driving distance from {origin} to {destination} is {distance} and takes around {duration}.\"\n",
    "        else:\n",
    "            return f\"Sorry, I couldn't find the shortest route from {origin} to {destination}.\"\n",
    "    else:\n",
    "        return get_deepseek_response(user_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58fbc75-5d29-494e-83a2-77d05ba1f799",
   "metadata": {},
   "source": [
    "## WhisperTranscription(SpeechToText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c729c19c-fd1d-49d6-993b-293462b3eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file_path, model_type, language):\n",
    "    model = whisper.load_model(model_type)\n",
    "    result = model.transcribe(file_path,\n",
    "                              language=language,\n",
    "                              task=\"transcribe\",\n",
    "                              )\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd37015d-33cd-484c-97c8-2fa81ea953a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English :  How far is Annanagar from Tambaram?\n"
     ]
    }
   ],
   "source": [
    "file_path = \"AnnaToTambaram.m4a\"\n",
    "en_transcribed_text = transcribe_audio(file_path, \"medium\", language=\"en\")\n",
    "print(\"English :\", en_transcribed_text)\n",
    "\n",
    "free_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a355ca0-5222-456e-bbf0-e003e1bdeaf6",
   "metadata": {},
   "source": [
    "## LLMLoading(DeepSeekR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c28b1d7a-3e4f-4d5b-98cd-f3adabf42d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5831dc82-d2fd-4eb1-b00e-dbb7c2722c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DeepSeek Model\n",
    "MODEL_NAME = \"deepseek-ai/deepseek-r1-distill-qwen-1.5b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16, device_map=\"cuda\")\n",
    "# Ensure PAD token is set correctly\n",
    "tokenizer.pad_token = tokenizer.eos_token  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5509524-2d26-48f0-832f-73dca020b5e0",
   "metadata": {},
   "source": [
    "## DeepSeek Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3de4bd5-8063-4820-811e-6f5d6457ea77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shortest driving distance from how far is annanagar to tambaram? is 27.9 km and takes around 45 mins.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "# user_input = \"What is the shortest distance from T-Nagar to Marina Beach?\"\n",
    "user_input=en_transcribed_text\n",
    "ai_response = process_user_prompt(user_input)\n",
    "print(ai_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b26483-629f-4e25-a402-7876416408fb",
   "metadata": {},
   "source": [
    "## PyTTS(TextToSpeech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d67c4b2-bf85-4458-b55b-040365d0d82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate :  200\n",
      "Volume :  1.0\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3 as tts\n",
    "engine = tts.init() # object creation\n",
    "\n",
    "\"\"\" RATE\"\"\"\n",
    "rate = engine.getProperty('rate')   # getting details of current speaking rate\n",
    "print (\"Rate : \",rate)                        #printing current voice rate\n",
    "engine.setProperty('rate', 125)     # setting up new voice rate\n",
    "\n",
    "\n",
    "\"\"\"VOLUME\"\"\"\n",
    "volume = engine.getProperty('volume')   #getting to know current volume level (min=0 and max=1)\n",
    "print (\"Volume : \",volume)                          #printing current volume level\n",
    "engine.setProperty('volume',1.0)    # setting up volume level  between 0 and 1\n",
    "\n",
    "\"\"\"VOICE\"\"\"\n",
    "voices = engine.getProperty('voices')       #getting details of current voice\n",
    "#engine.setProperty('voice', voices[0].id)  #changing index, changes voices. o for male\n",
    "engine.setProperty('voice', voices[0].id)   #changing index, changes voices. 1 for female\n",
    "\n",
    "engine.say(ai_response)\n",
    "engine.say('My current speaking rate is ' + str(rate))\n",
    "engine.runAndWait()\n",
    "if engine._inLoop:\n",
    "    engine.endLoop()\n",
    "engine.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
